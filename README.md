# DIY_LocalLLM

Taken largely from this [example](https://github.com/jiggy-ai/pydantic-chatcompletion/blob/master/example/book_info.py), the script demonstrates the method in [pydantic-chatcompletion](https://github.com/jiggy-ai/pydantic-chatcompletion/tree/master) and points to a private Phi-2 LLM running locally on [jan.ai](https://jan.ai/) server.   
